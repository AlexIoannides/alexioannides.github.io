<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Dr Alex Ioannides - data_science</title><link>https://alexioannides.github.io/</link><description>Financial engineer - (data) scientist - habitual coder</description><lastBuildDate>Sun, 09 Sep 2018 00:00:00 +0100</lastBuildDate><item><title>It Recently Occurred to Me…</title><link>https://alexioannides.github.io/it-recently-occurred-to-me.html</link><description>&lt;p&gt;&amp;#8230; I should get back into writing/blogging things that come to mind. For example, that type annotations and type-checking with &lt;code&gt;mypy&lt;/code&gt; are great tools for data scientists as well as day-to-day developers -&amp;nbsp;e.g.,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;circle_area&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;radius&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;pi&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;3.141&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pi&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Makes it so much …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr Alex Ioannides</dc:creator><pubDate>Sun, 09 Sep 2018 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:alexioannides.github.io,2018-09-09:/it-recently-occurred-to-me.html</guid><category>musings</category></item><item><title>Building a Data Science Platform for R&amp;D, Part 4 - Apache Zeppelin &amp; Scala Notebooks</title><link>https://alexioannides.github.io/building-a-data-science-platform-for-rd-part-4-apache-zeppelin-scala-notebooks.html</link><description>&lt;p&gt;&lt;img alt="zeppelin" src="https://alexioannides.github.io/images/data_science/data_science_platform_pt4/zeppelin.png" title="Apache Zeppelin"&gt;&lt;/p&gt;
&lt;p&gt;Parts &lt;a href="https://alexioannides.github.io/building-a-data-science-platform-for-rd-part-1-setting-up-aws.html" title="Part 1"&gt;one&lt;/a&gt;, &lt;a href="https://alexioannides.github.io/building-a-data-science-platform-for-rd-part-2-deploying-spark-on-aws-using-flintrock.html" title="Part 2"&gt;two&lt;/a&gt; and &lt;a href="https://alexioannides.github.io/building-a-data-science-platform-for-rd-part-2-deploying-spark-on-aws-using-flintrock.html" title="Part 3"&gt;three&lt;/a&gt; of this series of posts have taken us from creating an account on &lt;span class="caps"&gt;AWS&lt;/span&gt; to loading and interacting with data in Spark via R and R Studio. My vision of a Data Science platform for R&amp;amp;D is nearly complete - the only outstanding component is …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr Alex Ioannides</dc:creator><pubDate>Mon, 29 Aug 2016 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:alexioannides.github.io,2016-08-29:/building-a-data-science-platform-for-rd-part-4-apache-zeppelin-scala-notebooks.html</guid><category>big data</category><category>AWS</category><category>data processing</category></item><item><title>Building a Data Science Platform for R&amp;D, Part 3 - R, R Studio Server, SparkR &amp; Sparklyr</title><link>https://alexioannides.github.io/building-a-data-science-platform-for-rd-part-3-r-r-studio-server-sparkr-sparklyr.html</link><description>&lt;p&gt;&lt;img alt="Alt" src="https://alexioannides.github.io/images/data_science/data_science_platform_pt3/sparklyr.png" title="Command Line R"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexioannides.github.io/building-a-data-science-platform-for-rd-part-1-setting-up-aws.html" title="Part 1"&gt;Part 1&lt;/a&gt; and &lt;a href="https://alexioannides.github.io/building-a-data-science-platform-for-rd-part-2-deploying-spark-on-aws-using-flintrock.html" title="Part 2"&gt;Part 2&lt;/a&gt; of this series dealt with setting up &lt;span class="caps"&gt;AWS&lt;/span&gt;, loading data into S3, deploying a Spark cluster and using it to access our data. In this part we will deploy R and R Studio Server to our Spark cluster&amp;#8217;s master node and use it to …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr Alex Ioannides</dc:creator><pubDate>Mon, 22 Aug 2016 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:alexioannides.github.io,2016-08-22:/building-a-data-science-platform-for-rd-part-3-r-r-studio-server-sparkr-sparklyr.html</guid><category>big data</category><category>AWS</category><category>data processing</category><category>spark</category></item><item><title>Building a Data Science Platform for R&amp;D, Part 2 - Deploying Spark on AWS using Flintrock</title><link>https://alexioannides.github.io/building-a-data-science-platform-for-rd-part-2-deploying-spark-on-aws-using-flintrock.html</link><description>&lt;p&gt;&lt;img alt="Alt" src="https://alexioannides.github.io/images/data_science/data_science_platform_pt2/spark.png" title="spark"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexioannides.github.io/building-a-data-science-platform-for-rd-part-1-setting-up-aws.html" title="PartOne"&gt;Part 1&lt;/a&gt; in this series of blog posts describes how to setup &lt;span class="caps"&gt;AWS&lt;/span&gt; with some basic security and then load data into S3. This post walks-through the process of setting up a Spark cluster on &lt;span class="caps"&gt;AWS&lt;/span&gt; and accessing our S3 data from within&amp;nbsp;Spark.&lt;/p&gt;
&lt;p&gt;A key part of my vision …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr Alex Ioannides</dc:creator><pubDate>Thu, 18 Aug 2016 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:alexioannides.github.io,2016-08-18:/building-a-data-science-platform-for-rd-part-2-deploying-spark-on-aws-using-flintrock.html</guid><category>big data</category><category>AWS</category><category>data processing</category><category>spark</category></item><item><title>Building a Data Science Platform for R&amp;D, Part 1 - Setting-Up AWS</title><link>https://alexioannides.github.io/building-a-data-science-platform-for-rd-part-1-setting-up-aws.html</link><description>&lt;p&gt;&lt;img alt="Alt" src="https://alexioannides.github.io/images/data_science/data_science_platform_pt1/aws.png" title="AWS"&gt;&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s my vision: I get into the office and switch-on my laptop; then I start-up my &lt;a href="https://spark.apache.org"&gt;Spark&lt;/a&gt; cluster; I interact with it via &lt;a href="https://www.rstudio.com"&gt;RStudio&lt;/a&gt; to exploring a new dataset a client uploaded overnight; after getting a handle on what I want to do with it, I prototype an &lt;span class="caps"&gt;ETL …&lt;/span&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr Alex Ioannides</dc:creator><pubDate>Tue, 16 Aug 2016 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:alexioannides.github.io,2016-08-16:/building-a-data-science-platform-for-rd-part-1-setting-up-aws.html</guid><category>big data</category><category>AWS</category><category>data processing</category></item></channel></rss>